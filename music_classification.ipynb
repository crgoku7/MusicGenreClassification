{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7192d92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "from scipy import signal\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7a8f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir(\"Data/genres_original\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54e2411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Understanding the Audio File\n",
    "\n",
    "y, sr = librosa.load(\"Data/genres_original/blues/blues.00000.wav\")\n",
    "\n",
    "print(\"Sound Array :\", y)\n",
    "print(\"Sample Rate (KHz)\", sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0cab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trimming the Silence sequences sandwiching the audio file\n",
    "\n",
    "y, _ = librosa.effects.trim(y)\n",
    "print(y)\n",
    "\n",
    "#Observe no preceeding or succeding silence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44027ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2D Representation using Waveform\n",
    "\n",
    "plt.figure(figsize = (16,6))\n",
    "librosa.display.waveshow(y = y, sr = sr, color = \"#FF00AB\");\n",
    "plt.title(\"Waveform in Blues 0\", fontsize = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33519089",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decomposing the waveform based on the frequencies using FFT\n",
    "\n",
    "n_fft = 2048\n",
    "hop_length = 512\n",
    "\n",
    "D = np.abs(librosa.stft(y, n_fft = n_fft, hop_length = hop_length))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd5e6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(D)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14f1b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Log Frequency Spectogram from the FFT Signal\n",
    "#This also scales to the decibel system, as that is also log based.\n",
    "\n",
    "Deci = librosa.amplitude_to_db(D, ref = np.max)\n",
    "librosa.display.specshow(Deci, sr = sr, hop_length=hop_length, x_axis='time',y_axis='log',cmap = 'cool')\n",
    "\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a14683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mel Spectrogram form the data\n",
    "\n",
    "Mel_S = librosa.feature.melspectrogram(y =y, sr= sr)\n",
    "Deci_S = librosa.amplitude_to_db(Mel_S, ref = np.max)\n",
    "librosa.display.specshow(Deci_S, sr=sr, hop_length=hop_length, x_axis = 'time', y_axis = 'log',cmap = 'cool')\n",
    "plt.colorbar()\n",
    "plt.title(\"Mel Spectrogram\", fontsize = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f35128",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chroma Spectogram\n",
    "#This represents the energy distribution across pitch classes\n",
    "#Lets compare 3 genres, Rock, Pop and Classical\n",
    "\n",
    "rock, r_sr = librosa.load(\"Data/genres_original/rock/rock.00000.wav\")\n",
    "classical, c_sr = librosa.load(\"Data/genres_original/classical/classical.00000.wav\")\n",
    "pop, p_sr = librosa.load(\"Data/genres_original/pop/pop.00000.wav\")\n",
    "\n",
    "\n",
    "\n",
    "# Compute chroma spectrograms for each genre\n",
    "chroma_rock = librosa.feature.chroma_cqt(y=rock, sr=r_sr)\n",
    "chroma_cls = librosa.feature.chroma_cqt(y=classical, sr=c_sr)\n",
    "chroma_pop = librosa.feature.chroma_cqt(y=pop, sr=p_sr)\n",
    "\n",
    "\n",
    "# Plot the chroma spectrograms for each genre\n",
    "plt.figure(figsize=(12, 9))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "librosa.display.specshow(chroma_rock, sr=r_sr, x_axis='time', y_axis='chroma')\n",
    "plt.title('Chroma Spectrogram - Rock')\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "librosa.display.specshow(chroma_cls, sr=c_sr, x_axis='time', y_axis='chroma')\n",
    "plt.title('Chroma Spectrogram - Classical')\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "librosa.display.specshow(chroma_pop, sr=p_sr, x_axis='time', y_axis='chroma')\n",
    "plt.title('Chroma Spectrogram - Pop')\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f137a9",
   "metadata": {},
   "source": [
    "As can be seen through the chroma spectogram, the Rock and Classical Music seem to have the melodies consisting to a lot of notes at the same time, while the pop music(for general audience) consist very few notes at the same instant.\n",
    "Even if multiple notes are present at same time in Pop, they are usually harmonies i.e. 3rd or 5th of the root note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a522bec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute tempograms for each genre\n",
    "tempo_rock= librosa.beat.tempo(y=rock, sr=r_sr)\n",
    "tempogram_rock = librosa.feature.tempogram(y=rock, sr=r_sr, hop_length=512, win_length=384, window=np.hanning)\n",
    "\n",
    "tempo_cls = librosa.beat.tempo(y=classical, sr=c_sr)\n",
    "tempogram_cls = librosa.feature.tempogram(y=classical, sr=c_sr, hop_length=512, win_length=384, window=np.hanning)\n",
    "\n",
    "tempo_pop = librosa.beat.tempo(y=pop, sr=p_sr)\n",
    "tempogram_pop = librosa.feature.tempogram(y=pop, sr=p_sr, hop_length=512, win_length=384, window=np.hanning)\n",
    "\n",
    "# Plot the tempograms for each genre\n",
    "plt.figure(figsize=(12, 9))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "librosa.display.specshow(tempogram_rock, sr=r_sr, hop_length=512, x_axis='time', y_axis='tempo')\n",
    "plt.title('Tempogram - Rock (Tempo: {:.2f} BPM)'.format(tempo_rock[0]))\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "librosa.display.specshow(tempogram_cls, sr=c_sr, hop_length=512, x_axis='time', y_axis='tempo')\n",
    "plt.title('Tempogram - Classical (Tempo: {:.2f} BPM)'.format(tempo_cls[0]))\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "librosa.display.specshow(tempogram_pop, sr=p_sr, hop_length=512, x_axis='time', y_axis='tempo')\n",
    "plt.title('Tempogram - Pop (Tempo: {:.2f} BPM)'.format(tempo_pop[0]))\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32cf6ee",
   "metadata": {},
   "source": [
    "Not much can be said able the genres with just looking at the tempograms, \n",
    "so let's overlay the tempogram with the CQT spectogram, which provides the pitch over time for the audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050bea3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute CQT spectrograms for each genre\n",
    "cqt_rock = np.abs(librosa.cqt(rock, sr=r_sr, hop_length=512))\n",
    "cqt_cls = np.abs(librosa.cqt(classical, sr=c_sr, hop_length=512))\n",
    "cqt_pop = np.abs(librosa.cqt(pop, sr=p_sr, hop_length=512))\n",
    "\n",
    "# cqt_rock = sklearn.preprocessing.scale(cqt_rock, axis=1)\n",
    "# cqt_cls = sklearn.preprocessing.scale(cqt_cls, axis=1)\n",
    "# cqt_pop = sklearn.preprocessing.scale(cqt_pop, axis=1)\n",
    "# Plot the CQT spectrograms with tempograms overlaid for each genre\n",
    "plt.figure(figsize=(12, 9))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "librosa.display.specshow(librosa.amplitude_to_db(cqt_rock, ref=np.max), sr=r_sr, hop_length=512, x_axis='time', y_axis='cqt_note')\n",
    "librosa.display.specshow(tempogram_rock, sr=r_sr, hop_length=512, x_axis='time', y_axis='tempo', cmap='magma', alpha=0.6)\n",
    "plt.title('Rock CQT Spectrogram with Tempogram (Tempo: {:.2f} BPM)'.format(tempo_rock[0]))\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "librosa.display.specshow(librosa.amplitude_to_db(cqt_cls, ref=np.max), sr=c_sr, hop_length=512, x_axis='time', y_axis='cqt_note')\n",
    "librosa.display.specshow(tempogram_cls, sr=c_sr, hop_length=512, x_axis='time', y_axis='tempo', cmap='magma', alpha=0.6)\n",
    "plt.title('Classical CQT Spectrogram with Tempogram (Tempo: {:.2f} BPM)'.format(tempo_cls[0]))\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "librosa.display.specshow(librosa.amplitude_to_db(cqt_pop, ref=np.max), sr=p_sr, hop_length=512, x_axis='time', y_axis='cqt_note')\n",
    "librosa.display.specshow(tempogram_pop, sr=p_sr, hop_length=512, x_axis='time', y_axis='tempo', cmap='magma', alpha=0.6)\n",
    "plt.title('Pop CQT Spectrogram with Tempogram (Tempo: {:.2f} BPM)'.format(tempo_pop[0]))\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed253a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Harmonics and Percussive for the Audio file\n",
    "\n",
    "y_harm, y_perc = librosa.effects.hpss(y)\n",
    "plt.plot(y_harm, color = '#DD22AA')\n",
    "plt.plot(y_perc, color = '#11DD44')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e7c822",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5d9256-b31a-4425-a742-b90c79cc352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Data/features_3_sec.csv\")\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b1986b-6a20-494e-87e6-11a0554c1cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cd0630-0ee9-46a6-973a-ff88ba6fb80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba61250a-65d6-43c1-9df3-27fda6e0890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['filename','length'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cbacdd-baee-4e05-9dc5-de38bc204701",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1aa576-9f2b-44de-aa8a-c501468b7277",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae33180e-865e-4959-bc59-2eeb85c64995",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2255c43-bc45-41b3-ae65-5097587d5c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad1feba-b484-4f56-85a5-ba39bdb9d6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb30ea09-bd81-44f3-b5d9-98dfb7eb10c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d645d19-f97b-4a22-a08d-afd0687d2fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcd542b-cb9e-41be-93e8-a16f751465e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = pd.DataFrame(scaled_data, columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceb520d-bcba-442f-be84-c6d483736967",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50db6bf1-0e51-4b0f-baf9-7abb2cc09d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59436c86-fb7e-41f1-8856-f2c71ba72370",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,57):\n",
    "    pca_dummy = PCA(n_components = i)\n",
    "\n",
    "    dummy_trans = pca_dummy.fit_transform(X_scaled)\n",
    "\n",
    "    print(pca_dummy.explained_variance_ratio_.cumsum()[i-1],i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0234a867-b137-43d7-a3fa-9024c0b832a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 90% of variance can be explained using 24 components\n",
    "pca = PCA(n_components = 24)\n",
    "components = pca.fit_transform(X_scaled)\n",
    "\n",
    "X_pca = pd.DataFrame(components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36447c6f-ecac-490f-af2b-7c6c51c7a6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d81b22-7192-42bc-bf0f-6efe808adbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_pca,Y, test_size=0.2, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055f07a4-664f-49c8-8fd1-e8bdb3e25e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ab60bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333273f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Setting up the parameter grid for KNN\n",
    "param_found_knn = 1\n",
    "\n",
    "knn_params = {\n",
    "    'n_neighbors': range(1, 21),  # Considering a range that isn't too broad\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']  # Adding different distance metrics\n",
    "}\n",
    "knn_grid = GridSearchCV(KNeighborsClassifier(), knn_params, cv=5, scoring='accuracy', verbose=1)\n",
    "\n",
    "if not param_found_knn: \n",
    "    knn_grid.fit(X_train, y_train)\n",
    "\n",
    "    # Best parameters and best score\n",
    "    print(\"Best parameters for KNN:\", knn_grid.best_params_)\n",
    "    print(\"Best cross-validation score for KNN:\", knn_grid.best_score_)\n",
    "\n",
    "else:\n",
    "    knn_grid.best_params_ = {'metric': 'manhattan', 'n_neighbors': 4, 'weights': 'distance'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbc6f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Best parameters for KNN: {'metric': 'manhattan', 'n_neighbors': 4, 'weights': 'distance'}\n",
    "Best cross-validation score for KNN: 0.897649031270326\"\"\"\n",
    "\n",
    "\n",
    "# Training KNN with the best parameters\n",
    "knn_best = KNeighborsClassifier(**knn_grid.best_params_)\n",
    "knn_best.fit(X_train, y_train)\n",
    "y_pred_knn = knn_best.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "knn_accuracy = accuracy_score(y_test, y_pred_knn)\n",
    "knn_report = classification_report(y_test, y_pred_knn, output_dict=True)\n",
    "print(\"KNN Accuracy:\", knn_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb33ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform classification report into DataFrame\n",
    "knn_report_df = pd.DataFrame(knn_report).transpose()\n",
    "\n",
    "# Plotting the classification report\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(data=knn_report_df.iloc[:-1, :].drop(columns=['support']), annot=True, cmap='Blues', fmt='.2f')\n",
    "plt.title('KNN Classification Report')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a904f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix Visualization\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_knn), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('KNN Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f2e229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the parameter grid for Decision Trees\n",
    "\n",
    "param_found_dt = 1\n",
    "dt_params = {\n",
    "    'max_depth': range(5, 10),  # Max depth to prevent overfitting\n",
    "    'min_samples_split': range(2, 10, 2),  # Moderate range for minimum samples split\n",
    "    'min_samples_leaf': range(1, 5)  # Minimum samples per leaf to ensure generalization\n",
    "}\n",
    "dt_grid = GridSearchCV(DecisionTreeClassifier(random_state=42), dt_params, cv=5, scoring='accuracy', verbose=1)\n",
    "\n",
    "if not param_found_dt:\n",
    "    dt_grid.fit(X_train, y_train)\n",
    "\n",
    "    # Best parameters and best score\n",
    "    print(\"Best parameters for Decision Tree:\", dt_grid.best_params_)\n",
    "    print(\"Best cross-validation score for Decision Tree:\", dt_grid.best_score_)\n",
    "\n",
    "else:\n",
    "    dt_grid.best_params_ = {'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16501f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Best parameters for Decision Tree: {'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 4}\n",
    "Best cross-validation score for Decision Tree: 0.5446695016675785\"\"\"\n",
    "\n",
    "\n",
    "# Training Decision Tree with the best parameters\n",
    "dt_best = DecisionTreeClassifier(**dt_grid.best_params_, random_state=42)\n",
    "dt_best.fit(X_train, y_train)\n",
    "y_pred_dt = dt_best.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "dt_accuracy = accuracy_score(y_test, y_pred_dt)\n",
    "dt_report = classification_report(y_test, y_pred_dt, output_dict=True)\n",
    "print(\"Decision Tree Accuracy:\", dt_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5101b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform classification report into DataFrame\n",
    "dt_report_df = pd.DataFrame(dt_report).transpose()\n",
    "\n",
    "# Plotting the classification report\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(data=dt_report_df.iloc[:-1, :].drop(columns=['support']), annot=True, cmap='Blues', fmt='.2f')\n",
    "plt.title('Decision Tree Classification Report')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3237bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix Visualization\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_dt), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Decision Tree Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be62348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the parameter grid for SVM\n",
    "\n",
    "param_found_svm = 1\n",
    "svm_params = {\n",
    "    'C': [0.1, 1, 10],  # Regularization parameter\n",
    "    'gamma': ['scale', 'auto'],  # Kernel coefficient\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid']  # Different types of kernels\n",
    "}\n",
    "svm_grid = GridSearchCV(SVC(random_state=42), svm_params, cv=5, scoring='accuracy', verbose=1)\n",
    "if not param_found_svm:\n",
    "\n",
    "    svm_grid.fit(X_train, y_train)\n",
    "\n",
    "    # Best parameters and best score\n",
    "    print(\"Best parameters for SVM:\", svm_grid.best_params_)\n",
    "    print(\"Best cross-validation score for SVM:\", svm_grid.best_score_)\n",
    "\n",
    "else:\n",
    "    svm_grid.best_params_ = {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09aac53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Best parameters for SVM: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
    "Best cross-validation score for SVM: 0.8843858919960145\"\"\"\n",
    "\n",
    "# Training SVM with the best parameters\n",
    "svm_best = SVC(**svm_grid.best_params_, random_state=42)\n",
    "svm_best.fit(X_train, y_train)\n",
    "y_pred_svm = svm_best.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "svm_report = classification_report(y_test, y_pred_svm, output_dict=True)\n",
    "\n",
    "print(\"SVM Accuracy:\", svm_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473f790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform classification report into DataFrame\n",
    "svm_report_df = pd.DataFrame(svm_report).transpose()\n",
    "\n",
    "# Plotting the classification report\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(data=svm_report_df.iloc[:-1, :].drop(columns=['support']), annot=True, cmap='Blues', fmt='.2f')\n",
    "plt.title('SVM Classification Report')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86902e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_svm), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('SVM Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e362d8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "param_found_ada = 1\n",
    "adaboost_params = {\n",
    "    'n_estimators': [50, 100, 150, 200], # Number of models to iteratively train\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.5, 1] # Weight applied to each classifier at each boosting iteration\n",
    "}\n",
    "adaboost_grid = GridSearchCV(AdaBoostClassifier(random_state=42), adaboost_params, cv=5, scoring='accuracy', verbose=1)\n",
    "if not param_found_ada:\n",
    "# Setting up the parameter grid for Adaboost\n",
    "    \n",
    "    adaboost_grid.fit(X_train, y_train)\n",
    "\n",
    "    # Best parameters and best score\n",
    "    print(\"Best parameters for Adaboost:\", adaboost_grid.best_params_)\n",
    "    print(\"Best cross-validation score for Adaboost:\", adaboost_grid.best_score_)\n",
    "else:\n",
    "    adaboost_grid.best_params_ = {'learning_rate': 0.5, 'n_estimators': 50}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91448264",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Best parameters for Adaboost: {'learning_rate': 0.5, 'n_estimators': 50}\n",
    "Best cross-validation score for Adaboost: 0.3900166014272061\"\"\"\n",
    "\n",
    "# Training Adaboost with the best parameters\n",
    "adaboost_best = AdaBoostClassifier(**adaboost_grid.best_params_, random_state=42)\n",
    "adaboost_best.fit(X_train, y_train)\n",
    "y_pred_adaboost = adaboost_best.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "adaboost_accuracy = accuracy_score(y_test, y_pred_adaboost)\n",
    "adaboost_report = classification_report(y_test, y_pred_adaboost, output_dict=True)\n",
    "\n",
    "print(\"Adaboost Accuracy:\", adaboost_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc063d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform classification report into DataFrame\n",
    "adaboost_report_df = pd.DataFrame(adaboost_report).transpose()\n",
    "\n",
    "# Plotting the classification report\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(data=adaboost_report_df.iloc[:-1, :].drop(columns=['support']), annot=True, cmap='Blues', fmt='.2f')\n",
    "plt.title('Adaboost Classification Report')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20a307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_adaboost), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Adaboost Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aafdb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the parameter grid for Logistic Regression\n",
    "param_found_lr = 1\n",
    "\n",
    "lr_params = {\n",
    "    'C': [0.1, 1, 10, 100],  # Inverse of regularization strength\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear'],  # Algorithm to use in the optimization problem\n",
    "    'max_iter': [100, 200, 300]  # Maximum number of iterations taken for the solvers to converge\n",
    "}\n",
    "lr_grid = GridSearchCV(LogisticRegression(random_state=42), lr_params, cv=5)\n",
    "\n",
    "if not param_found_ada:\n",
    "    lr_grid.fit(X_train, y_train)\n",
    "\n",
    "    # Best parameters and best score\n",
    "    print(\"Best parameters for Logistic Regression:\", lr_grid.best_params_)\n",
    "    print(\"Best cross-validation score for Logistic Regression:\", lr_grid.best_score_)\n",
    "\n",
    "else:\n",
    "    lr_grid.best_params_= {'C': 100, 'max_iter': 100, 'solver': 'lbfgs'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230dac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Best parameters for Logistic Regression: {'C': 100, 'max_iter': 100, 'solver': 'lbfgs'}\n",
    "Best cross-validation score for Logistic Regression: 0.6521534500990528\"\"\"\n",
    "\n",
    "# Training Logistic Regression with the best parameters\n",
    "lr_best = LogisticRegression(**lr_grid.best_params_, random_state=42)\n",
    "lr_best.fit(X_train, y_train)\n",
    "y_pred_lr = lr_best.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "lr_accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "lr_report = classification_report(y_test, y_pred_lr, output_dict=True)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", lr_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cf0678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform classification report into DataFrame\n",
    "lr_report_df = pd.DataFrame(lr_report).transpose()\n",
    "\n",
    "# Plotting the classification report\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(data=lr_report_df.iloc[:-1, :].drop(columns=['support']), annot=True, cmap='Blues', fmt='.2f')\n",
    "plt.title('Logistic Regression Classification Report')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7234bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_lr), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Logistic Regression Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7c6e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model names\n",
    "models = ['KNN', 'Decision Tree', 'SVM', 'Adaboost', 'Logistic Regression']\n",
    "\n",
    "# Corresponding accuracies\n",
    "accuracies = [knn_accuracy, dt_accuracy, svm_accuracy, adaboost_accuracy, lr_accuracy]\n",
    "\n",
    "# Creating the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(models, accuracies, color='skyblue')  # Using a single color for all bars\n",
    "\n",
    "# Adding the percentage text on top of each bar\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.005, f'{yval:.2%}', ha='center', va='bottom')\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Comparison of Model Accuracies')\n",
    "plt.ylim(0, max(accuracies) + 0.05)  # Adjust the y-axis limits to give some space above the bars\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
