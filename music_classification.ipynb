{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "UgujQv5cG9fV",
      "metadata": {
        "id": "UgujQv5cG9fV"
      },
      "source": [
        "## Importing the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7192d92d",
      "metadata": {
        "id": "7192d92d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import librosa.display\n",
        "import IPython.display as ipd\n",
        "import warnings\n",
        "import os\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import soundfile as sf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7ab60bc",
      "metadata": {
        "id": "f7ab60bc"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4edf155e",
      "metadata": {
        "id": "4edf155e"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d455cc51",
      "metadata": {
        "id": "d455cc51"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UeKgoQqzUG5y",
      "metadata": {
        "id": "UeKgoQqzUG5y"
      },
      "source": [
        "## Dataset Exploration & Visualisation of different audio wafeforms"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "g6btsoUZUgzw",
      "metadata": {
        "id": "g6btsoUZUgzw"
      },
      "source": [
        "The Genres present in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac7a8f61",
      "metadata": {
        "id": "ac7a8f61",
        "outputId": "263edbdd-451b-4db0-ca5e-b5073c4ec828"
      },
      "outputs": [],
      "source": [
        "print(\"The genres present in the dataset are:\")\n",
        "print(os.listdir(\"Data/genres_original\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Uaa5lxH0WjRH",
      "metadata": {
        "id": "Uaa5lxH0WjRH"
      },
      "source": [
        "Understanding the audion files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f54e2411",
      "metadata": {
        "id": "f54e2411",
        "outputId": "5521ad62-424e-46be-bac0-c65311d0998d"
      },
      "outputs": [],
      "source": [
        "y, sr = librosa.load(\"Data/genres_original/blues/blues.00000.wav\")\n",
        "\n",
        "print(\"Sound Array :\", y)\n",
        "print(\"Sample Rate (KHz) =\", sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wG-R3dusWpDf",
      "metadata": {
        "id": "wG-R3dusWpDf"
      },
      "source": [
        "Trimming the Silence sequences in the audio files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba0cab97",
      "metadata": {
        "id": "ba0cab97",
        "outputId": "b68cb3cb-3385-4d59-8c5b-db8866ab1344"
      },
      "outputs": [],
      "source": [
        "y, _ = librosa.effects.trim(y)\n",
        "print(\"After trimming the silence sequences the sound array is:\")\n",
        "print(y)\n",
        "\n",
        "# Observe no preceeding or succeding silence"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cpssvGYnWypU",
      "metadata": {
        "id": "cpssvGYnWypU"
      },
      "source": [
        "2D Representation of audio using Waveform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44027ca7",
      "metadata": {
        "id": "44027ca7",
        "outputId": "ab957eef-2519-4762-9049-68ab38ea925c"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (16,6))\n",
        "librosa.display.waveshow(y = y, sr = sr, color = \"#FF00AB\");\n",
        "plt.title(\"Waveform in Blues 0\", fontsize = 24)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oI4n5wGbW6gk",
      "metadata": {
        "id": "oI4n5wGbW6gk"
      },
      "source": [
        "Decomposing the waveform based on the frequencies using Short time Fouries Transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33519089",
      "metadata": {
        "id": "33519089",
        "outputId": "d9ca89de-54e6-4548-f336-73d575246382"
      },
      "outputs": [],
      "source": [
        "n_fft = 2048\n",
        "hop_length = 512\n",
        "\n",
        "D = np.abs(librosa.stft(y, n_fft = n_fft, hop_length = hop_length))\n",
        "\n",
        "plt.plot(D)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6mx_iG3VXFLo",
      "metadata": {
        "id": "6mx_iG3VXFLo"
      },
      "source": [
        "Creating the Log Frequency Spectrogram from the transformed Signal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a14f1b50",
      "metadata": {
        "id": "a14f1b50",
        "outputId": "09f766cb-dbde-4374-c3ec-c2a16bfe843e"
      },
      "outputs": [],
      "source": [
        "# This also scales to the decibel system, as that is also log based.\n",
        "\n",
        "Deci = librosa.amplitude_to_db(D, ref = np.max)\n",
        "librosa.display.specshow(Deci, sr = sr, hop_length=hop_length, x_axis='time',y_axis='log',cmap = 'cool')\n",
        "\n",
        "plt.colorbar()\n",
        "plt.title(\"Log Frequency Spectrogram\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BVnlBY0BXOuc",
      "metadata": {
        "id": "BVnlBY0BXOuc"
      },
      "source": [
        "Plotting Mel Spectrogram from the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a14683a",
      "metadata": {
        "id": "9a14683a",
        "outputId": "d6ea230b-345d-47f6-f64e-985c34e39010"
      },
      "outputs": [],
      "source": [
        "Mel_S = librosa.feature.melspectrogram(y =y, sr= sr)\n",
        "Deci_S = librosa.amplitude_to_db(Mel_S, ref = np.max)\n",
        "librosa.display.specshow(Deci_S, sr=sr, hop_length=hop_length, x_axis = 'time', y_axis = 'log',cmap = 'cool')\n",
        "plt.colorbar()\n",
        "plt.title(\"Mel Spectrogram\", fontsize = 12)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yIKtPM88XV7-",
      "metadata": {
        "id": "yIKtPM88XV7-"
      },
      "source": [
        "Plotting Chroma Spectrogram which represents the energy distribution across pitch classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8f35128",
      "metadata": {
        "id": "e8f35128",
        "outputId": "004291fe-3bdc-4eb7-f35e-3fe2ca8ace94"
      },
      "outputs": [],
      "source": [
        "# Lets compare 3 genres, Rock, Pop and Classical\n",
        "\n",
        "rock, r_sr = librosa.load(\"Data/genres_original/rock/rock.00000.wav\")\n",
        "classical, c_sr = librosa.load(\"Data/genres_original/classical/classical.00000.wav\")\n",
        "pop, p_sr = librosa.load(\"Data/genres_original/pop/pop.00000.wav\")\n",
        "\n",
        "# Compute chroma spectrograms for each genre\n",
        "chroma_rock = librosa.feature.chroma_cqt(y=rock, sr=r_sr)\n",
        "chroma_cls = librosa.feature.chroma_cqt(y=classical, sr=c_sr)\n",
        "chroma_pop = librosa.feature.chroma_cqt(y=pop, sr=p_sr)\n",
        "\n",
        "# Plot the chroma spectrograms for each genre\n",
        "plt.figure(figsize=(12, 9))\n",
        "\n",
        "plt.subplot(3, 1, 1)\n",
        "librosa.display.specshow(chroma_rock, sr=r_sr, x_axis='time', y_axis='chroma')\n",
        "plt.title('Chroma Spectrogram - Rock')\n",
        "plt.colorbar()\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "librosa.display.specshow(chroma_cls, sr=c_sr, x_axis='time', y_axis='chroma')\n",
        "plt.title('Chroma Spectrogram - Classical')\n",
        "plt.colorbar()\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "librosa.display.specshow(chroma_pop, sr=p_sr, x_axis='time', y_axis='chroma')\n",
        "plt.title('Chroma Spectrogram - Pop')\n",
        "plt.colorbar()\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64f137a9",
      "metadata": {
        "id": "64f137a9"
      },
      "source": [
        "As can be seen through the chroma spectogram, the Rock and Classical Music seem to have the melodies consisting to a lot of notes at the same time, while the pop music(for general audience) consist very few notes at the same instant.\n",
        "Even if multiple notes are present at same time in Pop, they are usually harmonies i.e. 3rd or 5th of the root note."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6rd9QplxXk-D",
      "metadata": {
        "id": "6rd9QplxXk-D"
      },
      "source": [
        "Plotting Tempograms for a few genres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a522bec5",
      "metadata": {
        "id": "a522bec5",
        "outputId": "05d14f85-4a73-4cc5-92ec-ead0b24cbf7a"
      },
      "outputs": [],
      "source": [
        "tempo_rock= librosa.beat.tempo(y=rock, sr=r_sr)\n",
        "tempogram_rock = librosa.feature.tempogram(y=rock, sr=r_sr, hop_length=512, win_length=384, window=np.hanning)\n",
        "\n",
        "tempo_cls = librosa.beat.tempo(y=classical, sr=c_sr)\n",
        "tempogram_cls = librosa.feature.tempogram(y=classical, sr=c_sr, hop_length=512, win_length=384, window=np.hanning)\n",
        "\n",
        "tempo_pop = librosa.beat.tempo(y=pop, sr=p_sr)\n",
        "tempogram_pop = librosa.feature.tempogram(y=pop, sr=p_sr, hop_length=512, win_length=384, window=np.hanning)\n",
        "\n",
        "# Plot the tempograms for each genre\n",
        "plt.figure(figsize=(12, 9))\n",
        "\n",
        "plt.subplot(3, 1, 1)\n",
        "librosa.display.specshow(tempogram_rock, sr=r_sr, hop_length=512, x_axis='time', y_axis='tempo')\n",
        "plt.title('Tempogram - Rock (Tempo: {:.2f} BPM)'.format(tempo_rock[0]))\n",
        "plt.colorbar()\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "librosa.display.specshow(tempogram_cls, sr=c_sr, hop_length=512, x_axis='time', y_axis='tempo')\n",
        "plt.title('Tempogram - Classical (Tempo: {:.2f} BPM)'.format(tempo_cls[0]))\n",
        "plt.colorbar()\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "librosa.display.specshow(tempogram_pop, sr=p_sr, hop_length=512, x_axis='time', y_axis='tempo')\n",
        "plt.title('Tempogram - Pop (Tempo: {:.2f} BPM)'.format(tempo_pop[0]))\n",
        "plt.colorbar()\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c32cf6ee",
      "metadata": {
        "id": "c32cf6ee"
      },
      "source": [
        "Not much can be said able the genres with just looking at the tempograms,\n",
        "so let's overlay the tempogram with the CQT spectogram, which provides the pitch over time for the audio file."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MUES3sImXuyY",
      "metadata": {
        "id": "MUES3sImXuyY"
      },
      "source": [
        "Plotting CQT Spectrograms for a few genres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "050bea3e",
      "metadata": {
        "id": "050bea3e",
        "outputId": "f83e599b-0647-4ff2-f1fa-e4759aaf5681"
      },
      "outputs": [],
      "source": [
        "cqt_rock = np.abs(librosa.cqt(rock, sr=r_sr, hop_length=512))\n",
        "cqt_cls = np.abs(librosa.cqt(classical, sr=c_sr, hop_length=512))\n",
        "cqt_pop = np.abs(librosa.cqt(pop, sr=p_sr, hop_length=512))\n",
        "\n",
        "# Plot the CQT spectrograms with tempograms overlaid for each genre\n",
        "plt.figure(figsize=(12, 9))\n",
        "\n",
        "plt.subplot(3, 1, 1)\n",
        "librosa.display.specshow(librosa.amplitude_to_db(cqt_rock, ref=np.max), sr=r_sr, hop_length=512, x_axis='time', y_axis='cqt_note')\n",
        "librosa.display.specshow(tempogram_rock, sr=r_sr, hop_length=512, x_axis='time', y_axis='tempo', cmap='magma', alpha=0.6)\n",
        "plt.title('Rock CQT Spectrogram with Tempogram (Tempo: {:.2f} BPM)'.format(tempo_rock[0]))\n",
        "plt.colorbar()\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "librosa.display.specshow(librosa.amplitude_to_db(cqt_cls, ref=np.max), sr=c_sr, hop_length=512, x_axis='time', y_axis='cqt_note')\n",
        "librosa.display.specshow(tempogram_cls, sr=c_sr, hop_length=512, x_axis='time', y_axis='tempo', cmap='magma', alpha=0.6)\n",
        "plt.title('Classical CQT Spectrogram with Tempogram (Tempo: {:.2f} BPM)'.format(tempo_cls[0]))\n",
        "plt.colorbar()\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "librosa.display.specshow(librosa.amplitude_to_db(cqt_pop, ref=np.max), sr=p_sr, hop_length=512, x_axis='time', y_axis='cqt_note')\n",
        "librosa.display.specshow(tempogram_pop, sr=p_sr, hop_length=512, x_axis='time', y_axis='tempo', cmap='magma', alpha=0.6)\n",
        "plt.title('Pop CQT Spectrogram with Tempogram (Tempo: {:.2f} BPM)'.format(tempo_pop[0]))\n",
        "plt.colorbar()\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "z0KrojoDX39h",
      "metadata": {
        "id": "z0KrojoDX39h"
      },
      "source": [
        "Harmonics & Percussive for the audio files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed253a3d",
      "metadata": {
        "id": "ed253a3d",
        "outputId": "970f10d4-9062-449f-916b-c593fe17dc5f"
      },
      "outputs": [],
      "source": [
        "y_harm, y_perc = librosa.effects.hpss(y)\n",
        "plt.plot(y_harm, color = '#DD22AA')\n",
        "plt.plot(y_perc, color = '#11DD44')\n",
        "plt.title(\"Harmonics & Percussive\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e5d9256-b31a-4425-a742-b90c79cc352e",
      "metadata": {
        "id": "3e5d9256-b31a-4425-a742-b90c79cc352e",
        "outputId": "6f5939d4-08bf-47c7-e730-6d399105bcf3"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"Data/features_3_sec.csv\")\n",
        "print(data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3mIMT9ODHHOC",
      "metadata": {
        "id": "3mIMT9ODHHOC"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_CK9eUitT2sB",
      "metadata": {
        "id": "_CK9eUitT2sB"
      },
      "source": [
        "Having a look at the data & the information about its features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9b1986b-6a20-494e-87e6-11a0554c1cb6",
      "metadata": {
        "id": "a9b1986b-6a20-494e-87e6-11a0554c1cb6",
        "outputId": "fe8d9e82-cd81-45b3-a6c3-7352d76ecf3e"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31cd0630-0ee9-46a6-973a-ff88ba6fb80a",
      "metadata": {
        "id": "31cd0630-0ee9-46a6-973a-ff88ba6fb80a",
        "outputId": "b38c0c78-9699-4e7b-c124-4d306f39fdce"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48c085e5",
      "metadata": {
        "id": "48c085e5",
        "outputId": "a81b1cc9-9585-4f75-ace0-009f22ef12c7"
      },
      "outputs": [],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "R4w_cflSHL4o",
      "metadata": {
        "id": "R4w_cflSHL4o"
      },
      "source": [
        "#### Box Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e3919ac",
      "metadata": {
        "id": "3e3919ac",
        "outputId": "e1be52d1-d99b-4c28-fd83-ecefc9420153"
      },
      "outputs": [],
      "source": [
        "# Box plot of label vs tempo\n",
        "x = data[[\"label\", \"tempo\"]]\n",
        "\n",
        "f, ax = plt.subplots(figsize=(16, 9));\n",
        "sns.boxplot(x = \"label\", y = \"tempo\", data = x, palette = 'Blues')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "A7jT_H1lHQNV",
      "metadata": {
        "id": "A7jT_H1lHQNV"
      },
      "source": [
        "#### CorrelationHeatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea9b7e6d",
      "metadata": {
        "id": "ea9b7e6d",
        "outputId": "f8e1983b-aa47-4f57-88a7-8e0c74196411"
      },
      "outputs": [],
      "source": [
        "# Heat map for the mean variables\n",
        "mean_cols = [col for col in data.columns if 'mean' in col]\n",
        "\n",
        "corr = data[mean_cols].corr()\n",
        "f, ax = plt.subplots(figsize=(16, 11))\n",
        "\n",
        "sns.heatmap(corr, cmap = 'Blues')\n",
        "plt.title('Correlation Heatmap (for the MEAN variables)', fontsize = 20)\n",
        "plt.xticks(fontsize = 10)\n",
        "plt.yticks(fontsize = 10)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a73de292",
      "metadata": {
        "id": "a73de292",
        "outputId": "ba472987-ab42-4f29-99b1-14650db32be2"
      },
      "outputs": [],
      "source": [
        "# Heat map for Variance variables\n",
        "var_cols = [col for col in data.columns if 'var' in col]\n",
        "\n",
        "corr = data[var_cols].corr()\n",
        "f, ax = plt.subplots(figsize=(16, 11))\n",
        "\n",
        "sns.heatmap(corr, cmap = 'Blues')\n",
        "plt.title('Correlation Heatmap (for the VARIANCE variables)', fontsize = 20)\n",
        "plt.xticks(fontsize = 10)\n",
        "plt.yticks(fontsize = 10)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rP9xdVTsHWFW",
      "metadata": {
        "id": "rP9xdVTsHWFW"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba61250a-65d6-43c1-9df3-27fda6e0890e",
      "metadata": {
        "id": "ba61250a-65d6-43c1-9df3-27fda6e0890e"
      },
      "outputs": [],
      "source": [
        "data.drop(['filename','length'], axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64cbacdd-baee-4e05-9dc5-de38bc204701",
      "metadata": {
        "id": "64cbacdd-baee-4e05-9dc5-de38bc204701",
        "outputId": "08442adc-f27a-4da6-d4d0-563722b3b443"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de1aa576-9f2b-44de-aa8a-c501468b7277",
      "metadata": {
        "id": "de1aa576-9f2b-44de-aa8a-c501468b7277"
      },
      "outputs": [],
      "source": [
        "X = data.iloc[:,:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2255c43-bc45-41b3-ae65-5097587d5c90",
      "metadata": {
        "id": "a2255c43-bc45-41b3-ae65-5097587d5c90"
      },
      "outputs": [],
      "source": [
        "Y = data.iloc[:,-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aad1feba-b484-4f56-85a5-ba39bdb9d6d0",
      "metadata": {
        "id": "aad1feba-b484-4f56-85a5-ba39bdb9d6d0",
        "outputId": "ca2f9ae6-f5ac-4ceb-f866-132be13671c4"
      },
      "outputs": [],
      "source": [
        "Y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cRzpW0HMHg17",
      "metadata": {
        "id": "cRzpW0HMHg17"
      },
      "source": [
        "#### Scaling the features of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb30ea09-bd81-44f3-b5d9-98dfb7eb10c1",
      "metadata": {
        "id": "fb30ea09-bd81-44f3-b5d9-98dfb7eb10c1"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d645d19-f97b-4a22-a08d-afd0687d2fdf",
      "metadata": {
        "id": "2d645d19-f97b-4a22-a08d-afd0687d2fdf"
      },
      "outputs": [],
      "source": [
        "columns = X.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dcd542b-cb9e-41be-93e8-a16f751465e8",
      "metadata": {
        "id": "5dcd542b-cb9e-41be-93e8-a16f751465e8"
      },
      "outputs": [],
      "source": [
        "X_scaled = pd.DataFrame(scaled_data, columns = columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ceb520d-bcba-442f-be84-c6d483736967",
      "metadata": {
        "id": "0ceb520d-bcba-442f-be84-c6d483736967",
        "outputId": "bdaefdfb-a736-4304-d720-790bc4518c3b"
      },
      "outputs": [],
      "source": [
        "X_scaled.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iJsy19ErHlU8",
      "metadata": {
        "id": "iJsy19ErHlU8"
      },
      "source": [
        "#### Implementing Principal Component Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Xwh6rLwOTj53",
      "metadata": {
        "id": "Xwh6rLwOTj53"
      },
      "source": [
        "Checking the Variance explained by different number of components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59436c86-fb7e-41f1-8856-f2c71ba72370",
      "metadata": {
        "id": "59436c86-fb7e-41f1-8856-f2c71ba72370",
        "outputId": "45cc1119-f200-4e05-ab6a-05e52ee5ea80"
      },
      "outputs": [],
      "source": [
        "for i in range(1,57):\n",
        "    pca_dummy = PCA(n_components = i)\n",
        "\n",
        "    dummy_trans = pca_dummy.fit_transform(X_scaled)\n",
        "\n",
        "    print(\"For\", i,\"number of components Explained Variance Ratio =\", pca_dummy.explained_variance_ratio_.cumsum()[i-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OLudFnEqTMym",
      "metadata": {
        "id": "OLudFnEqTMym"
      },
      "source": [
        "Since, 90% of the variance can be explained by taking 24 components so, the components are reduced to 24"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0234a867-b137-43d7-a3fa-9024c0b832a2",
      "metadata": {
        "id": "0234a867-b137-43d7-a3fa-9024c0b832a2"
      },
      "outputs": [],
      "source": [
        "# 90% of variance can be explained using 24 components\n",
        "pca = PCA(n_components = 24)\n",
        "components = pca.fit_transform(X_scaled)\n",
        "\n",
        "X_pca = pd.DataFrame(components)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vuYH03ZsTeQH",
      "metadata": {
        "id": "vuYH03ZsTeQH"
      },
      "source": [
        "Splitting the reduced data in train & test part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20d81b22-7192-42bc-bf0f-6efe808adbe3",
      "metadata": {
        "id": "20d81b22-7192-42bc-bf0f-6efe808adbe3"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_pca,Y, test_size=0.2, random_state=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "055f07a4-664f-49c8-8fd1-e8bdb3e25e83",
      "metadata": {
        "id": "055f07a4-664f-49c8-8fd1-e8bdb3e25e83",
        "outputId": "8ea14e89-93b8-4427-da4d-77478ae6f571"
      },
      "outputs": [],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3UPPu1YRIEWQ",
      "metadata": {
        "id": "3UPPu1YRIEWQ"
      },
      "source": [
        "## Implementing different models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "whP0F3weII5H",
      "metadata": {
        "id": "whP0F3weII5H"
      },
      "source": [
        "#### Implementing K Nearest Neighbors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "G-dL1-A5PNnf",
      "metadata": {
        "id": "G-dL1-A5PNnf"
      },
      "source": [
        "Grid Search for finding best parameters for K Nearest Neighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "333273f9",
      "metadata": {
        "id": "333273f9"
      },
      "outputs": [],
      "source": [
        "# Setting up the parameter grid for KNN\n",
        "param_found_knn = 1\n",
        "\n",
        "knn_params = {\n",
        "    'n_neighbors': range(1, 21),  # Considering a range that isn't too broad\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan']  # Adding different distance metrics\n",
        "}\n",
        "knn_grid = GridSearchCV(KNeighborsClassifier(), knn_params, cv=5, scoring='accuracy', verbose=1)\n",
        "\n",
        "if not param_found_knn:\n",
        "    knn_grid.fit(X_train, y_train)\n",
        "\n",
        "    # Best parameters and best score\n",
        "    print(\"Best parameters for KNN:\", knn_grid.best_params_)\n",
        "    print(\"Best cross-validation score for KNN:\", knn_grid.best_score_)\n",
        "\n",
        "else:\n",
        "    knn_grid.best_params_ = {'metric': 'manhattan', 'n_neighbors': 4, 'weights': 'distance'}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1PITjCrZPbAZ",
      "metadata": {
        "id": "1PITjCrZPbAZ"
      },
      "source": [
        "Best parameters for KNN: {'metric': 'manhattan', 'n_neighbors': 4, 'weights': 'distance'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bbc6f8c",
      "metadata": {
        "id": "4bbc6f8c",
        "outputId": "d9e52ac9-f1d9-4f2e-dd6a-fc0d143171c6"
      },
      "outputs": [],
      "source": [
        "# Training KNN with the best parameters\n",
        "knn_best = KNeighborsClassifier(**knn_grid.best_params_)\n",
        "knn_best.fit(X_train, y_train)\n",
        "y_pred_knn_test = knn_best.predict(X_test)\n",
        "y_pred_knn_train = knn_best.predict(X_train)\n",
        "\n",
        "# Evaluation\n",
        "knn_accuracy_test = accuracy_score(y_test, y_pred_knn_test)\n",
        "knn_accuracy_train = accuracy_score(y_train, y_pred_knn_train)\n",
        "knn_report = classification_report(y_test, y_pred_knn_test, output_dict=True)\n",
        "print(\"Accuracy using KNN =\", knn_accuracy_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cwwm15WmPoDP",
      "metadata": {
        "id": "cwwm15WmPoDP"
      },
      "source": [
        "Classfication Report for K Nearest Neighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfb33ae7",
      "metadata": {
        "id": "cfb33ae7",
        "outputId": "d45f7786-37be-4806-a03b-9a311e97cf61"
      },
      "outputs": [],
      "source": [
        "# Transform classification report into DataFrame\n",
        "knn_report_df = pd.DataFrame(knn_report).transpose()\n",
        "\n",
        "# Plotting the classification report\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(data=knn_report_df.iloc[:-1, :].drop(columns=['support']), annot=True, cmap='Blues', fmt='.2f')\n",
        "plt.title('KNN Classification Report')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "R4LNxCUEPtgx",
      "metadata": {
        "id": "R4LNxCUEPtgx"
      },
      "source": [
        "Confusion Matrix for K Nearest Neighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a904f4a",
      "metadata": {
        "id": "9a904f4a",
        "outputId": "6f559bda-b3b2-48de-c001-de188e0acfba"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix Visualization\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred_knn_test), annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('KNN Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "J0z75buVIPQk",
      "metadata": {
        "id": "J0z75buVIPQk"
      },
      "source": [
        "#### Implementing Decision Trees"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dozMMWACP04C",
      "metadata": {
        "id": "dozMMWACP04C"
      },
      "source": [
        "Grid Search for finding best parameters for Decision Trees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81f2e229",
      "metadata": {
        "id": "81f2e229"
      },
      "outputs": [],
      "source": [
        "# Setting up the parameter grid for Decision Trees\n",
        "\n",
        "param_found_dt = 1\n",
        "dt_params = {\n",
        "    'max_depth': range(5, 10),  # Max depth to prevent overfitting\n",
        "    'min_samples_split': range(2, 10, 2),  # Moderate range for minimum samples split\n",
        "    'min_samples_leaf': range(1, 5)  # Minimum samples per leaf to ensure generalization\n",
        "}\n",
        "dt_grid = GridSearchCV(DecisionTreeClassifier(random_state=42), dt_params, cv=5, scoring='accuracy', verbose=1)\n",
        "\n",
        "if not param_found_dt:\n",
        "    dt_grid.fit(X_train, y_train)\n",
        "\n",
        "    # Best parameters and best score\n",
        "    print(\"Best parameters for Decision Tree:\", dt_grid.best_params_)\n",
        "    print(\"Best cross-validation score for Decision Tree:\", dt_grid.best_score_)\n",
        "\n",
        "else:\n",
        "    dt_grid.best_params_ = {'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 4}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eR4AHRQwP4gi",
      "metadata": {
        "id": "eR4AHRQwP4gi"
      },
      "source": [
        "Best parameters for Decision Tree: {'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 4}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16501f1b",
      "metadata": {
        "id": "16501f1b",
        "outputId": "6bdad2b3-37be-4cda-b297-bd3f7a5450ee"
      },
      "outputs": [],
      "source": [
        "# Training Decision Tree with the best parameters\n",
        "dt_best = DecisionTreeClassifier(**dt_grid.best_params_, random_state=42)\n",
        "dt_best.fit(X_train, y_train)\n",
        "y_pred_dt_test = dt_best.predict(X_test)\n",
        "y_pred_dt_train = dt_best.predict(X_train)\n",
        "\n",
        "# Evaluation\n",
        "dt_accuracy_test = accuracy_score(y_test, y_pred_dt_test)\n",
        "dt_accuracy_train = accuracy_score(y_train, y_pred_dt_train)\n",
        "dt_report = classification_report(y_test, y_pred_dt_test, output_dict=True)\n",
        "print(\"Accuracy using Decision Tree =\", dt_accuracy_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BhnNNcLbP-mQ",
      "metadata": {
        "id": "BhnNNcLbP-mQ"
      },
      "source": [
        "Classification Report for Decision Trees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5101b06",
      "metadata": {
        "id": "b5101b06",
        "outputId": "093dcfd7-06ab-4959-d590-36218b09ce40"
      },
      "outputs": [],
      "source": [
        "# Transform classification report into DataFrame\n",
        "dt_report_df = pd.DataFrame(dt_report).transpose()\n",
        "\n",
        "# Plotting the classification report\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(data=dt_report_df.iloc[:-1, :].drop(columns=['support']), annot=True, cmap='Blues', fmt='.2f')\n",
        "plt.title('Decision Tree Classification Report')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tUTQ9x__QGfR",
      "metadata": {
        "id": "tUTQ9x__QGfR"
      },
      "source": [
        "Confusion Matrix for Decision Trees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3237bcb",
      "metadata": {
        "id": "e3237bcb",
        "outputId": "d956dfeb-9ce0-421e-fb8b-40c099fc8d8e"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix Visualization\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred_dt_test), annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Decision Tree Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sJPYpUgCIT5A",
      "metadata": {
        "id": "sJPYpUgCIT5A"
      },
      "source": [
        "#### Implementing Support Vector Machines"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VNLIVTJAQK_c",
      "metadata": {
        "id": "VNLIVTJAQK_c"
      },
      "source": [
        "Grid Search for finding best parameters for Support Vector Machines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7be62348",
      "metadata": {
        "id": "7be62348"
      },
      "outputs": [],
      "source": [
        "# Setting up the parameter grid for SVM\n",
        "\n",
        "param_found_svm = 1\n",
        "svm_params = {\n",
        "    'C': [0.1, 1, 10],  # Regularization parameter\n",
        "    'gamma': ['scale', 'auto'],  # Kernel coefficient\n",
        "    'kernel': ['rbf', 'poly', 'sigmoid']  # Different types of kernels\n",
        "}\n",
        "svm_grid = GridSearchCV(SVC(random_state=42), svm_params, cv=5, scoring='accuracy', verbose=1)\n",
        "if not param_found_svm:\n",
        "\n",
        "    svm_grid.fit(X_train, y_train)\n",
        "\n",
        "    # Best parameters and best score\n",
        "    print(\"Best parameters for SVM:\", svm_grid.best_params_)\n",
        "    print(\"Best cross-validation score for SVM:\", svm_grid.best_score_)\n",
        "\n",
        "else:\n",
        "    svm_grid.best_params_ = {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-1WtLR3BQSHE",
      "metadata": {
        "id": "-1WtLR3BQSHE"
      },
      "source": [
        "Best parameters for SVM: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c09aac53",
      "metadata": {
        "id": "c09aac53",
        "outputId": "2fef652e-4dff-44d3-88d3-767d9f4374fb"
      },
      "outputs": [],
      "source": [
        "# Training SVM with the best parameters\n",
        "svm_best = SVC(**svm_grid.best_params_, random_state=42)\n",
        "svm_best.fit(X_train, y_train)\n",
        "y_pred_svm_test = svm_best.predict(X_test)\n",
        "y_pred_svm_train = svm_best.predict(X_train)\n",
        "\n",
        "# Evaluation\n",
        "svm_accuracy_test = accuracy_score(y_test, y_pred_svm_test)\n",
        "svm_accuracy_train = accuracy_score(y_train, y_pred_svm_train)\n",
        "svm_report = classification_report(y_test, y_pred_svm_test, output_dict=True)\n",
        "\n",
        "print(\"Accuracy using SVM =\", svm_accuracy_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "x2shfCFsQUty",
      "metadata": {
        "id": "x2shfCFsQUty"
      },
      "source": [
        "Classification Report for Support Vector Machines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "473f790f",
      "metadata": {
        "id": "473f790f",
        "outputId": "91fcff29-9bad-417c-b257-94e305c9d8de"
      },
      "outputs": [],
      "source": [
        "# Transform classification report into DataFrame\n",
        "svm_report_df = pd.DataFrame(svm_report).transpose()\n",
        "\n",
        "# Plotting the classification report\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(data=svm_report_df.iloc[:-1, :].drop(columns=['support']), annot=True, cmap='Blues', fmt='.2f')\n",
        "plt.title('SVM Classification Report')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mz_cMghbQbaG",
      "metadata": {
        "id": "mz_cMghbQbaG"
      },
      "source": [
        "Confusion Matrix for Support Vector Machines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d86902e1",
      "metadata": {
        "id": "d86902e1",
        "outputId": "5b5e8331-9dbe-4e5e-8627-029cc10e7b05"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred_svm_test), annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('SVM Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TpysK9f2IaQ-",
      "metadata": {
        "id": "TpysK9f2IaQ-"
      },
      "source": [
        "#### Implementing Adaboost"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3XOajx14QgEQ",
      "metadata": {
        "id": "3XOajx14QgEQ"
      },
      "source": [
        "Grid Search for finding best parameters for Adaboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e362d8c3",
      "metadata": {
        "id": "e362d8c3"
      },
      "outputs": [],
      "source": [
        "param_found_ada = 1\n",
        "adaboost_params = {\n",
        "    'n_estimators': [50, 100, 150, 200], # Number of models to iteratively train\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.5, 1] # Weight applied to each classifier at each boosting iteration\n",
        "}\n",
        "adaboost_grid = GridSearchCV(AdaBoostClassifier(random_state=42), adaboost_params, cv=5, scoring='accuracy', verbose=1)\n",
        "if not param_found_ada:\n",
        "# Setting up the parameter grid for Adaboost\n",
        "\n",
        "    adaboost_grid.fit(X_train, y_train)\n",
        "\n",
        "    # Best parameters and best score\n",
        "    print(\"Best parameters for Adaboost:\", adaboost_grid.best_params_)\n",
        "    print(\"Best cross-validation score for Adaboost:\", adaboost_grid.best_score_)\n",
        "else:\n",
        "    adaboost_grid.best_params_ = {'learning_rate': 0.5, 'n_estimators': 50}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "S3I2v_3eQjsr",
      "metadata": {
        "id": "S3I2v_3eQjsr"
      },
      "source": [
        "Best parameters for Adaboost: {'learning_rate': 0.5, 'n_estimators': 50}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91448264",
      "metadata": {
        "id": "91448264",
        "outputId": "f903a7d4-c6fd-4b29-b566-63c5f38f2d18"
      },
      "outputs": [],
      "source": [
        "# Training Adaboost with the best parameters\n",
        "adaboost_best = AdaBoostClassifier(**adaboost_grid.best_params_, random_state=42)\n",
        "adaboost_best.fit(X_train, y_train)\n",
        "y_pred_adaboost_test = adaboost_best.predict(X_test)\n",
        "y_pred_adaboost_train = adaboost_best.predict(X_train)\n",
        "\n",
        "# Evaluation\n",
        "adaboost_accuracy_test = accuracy_score(y_test, y_pred_adaboost_test)\n",
        "adaboost_accuracy_train = accuracy_score(y_train, y_pred_adaboost_train)\n",
        "adaboost_report = classification_report(y_test, y_pred_adaboost_test, output_dict=True)\n",
        "\n",
        "print(\"Accuracy using Adaboost =\", adaboost_accuracy_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1Mn2bDe3QqFN",
      "metadata": {
        "id": "1Mn2bDe3QqFN"
      },
      "source": [
        "Classification Report for Adaboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfc063d8",
      "metadata": {
        "id": "dfc063d8",
        "outputId": "904b9dbf-db18-403b-942a-247da5b67e87"
      },
      "outputs": [],
      "source": [
        "# Transform classification report into DataFrame\n",
        "adaboost_report_df = pd.DataFrame(adaboost_report).transpose()\n",
        "\n",
        "# Plotting the classification report\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(data=adaboost_report_df.iloc[:-1, :].drop(columns=['support']), annot=True, cmap='Blues', fmt='.2f')\n",
        "plt.title('Adaboost Classification Report')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "H6vgqIpgQtis",
      "metadata": {
        "id": "H6vgqIpgQtis"
      },
      "source": [
        "Confusion Matrix for Adaboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c20a307b",
      "metadata": {
        "id": "c20a307b",
        "outputId": "24632e67-f545-4e6d-fd08-a543462f77d8"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred_adaboost_test), annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Adaboost Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "s4_vPTFWIfS6",
      "metadata": {
        "id": "s4_vPTFWIfS6"
      },
      "source": [
        "#### Implementing Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "m21rYIh6QwvV",
      "metadata": {
        "id": "m21rYIh6QwvV"
      },
      "source": [
        "Grid Search for finding best parameters for Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4aafdb41",
      "metadata": {
        "id": "4aafdb41"
      },
      "outputs": [],
      "source": [
        "# Setting up the parameter grid for Logistic Regression\n",
        "param_found_lr = 1\n",
        "\n",
        "lr_params = {\n",
        "    'C': [0.1, 1, 10, 100],  # Inverse of regularization strength\n",
        "    'solver': ['newton-cg', 'lbfgs', 'liblinear'],  # Algorithm to use in the optimization problem\n",
        "    'max_iter': [100, 200, 300]  # Maximum number of iterations taken for the solvers to converge\n",
        "}\n",
        "lr_grid = GridSearchCV(LogisticRegression(random_state=42), lr_params, cv=5)\n",
        "\n",
        "if not param_found_ada:\n",
        "    lr_grid.fit(X_train, y_train)\n",
        "\n",
        "    # Best parameters and best score\n",
        "    print(\"Best parameters for Logistic Regression:\", lr_grid.best_params_)\n",
        "    print(\"Best cross-validation score for Logistic Regression:\", lr_grid.best_score_)\n",
        "\n",
        "else:\n",
        "    lr_grid.best_params_= {'C': 100, 'max_iter': 100, 'solver': 'lbfgs'}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ztGH3r0YQ1ED",
      "metadata": {
        "id": "ztGH3r0YQ1ED"
      },
      "source": [
        "Best parameters for Logistic Regression: {'C': 100, 'max_iter': 100, 'solver': 'lbfgs'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "230dac61",
      "metadata": {
        "id": "230dac61",
        "outputId": "33eecf53-6bb6-4501-9f40-8ed8606b5fa0"
      },
      "outputs": [],
      "source": [
        "# Training Logistic Regression with the best parameters\n",
        "lr_best = LogisticRegression(**lr_grid.best_params_, random_state=42)\n",
        "lr_best.fit(X_train, y_train)\n",
        "y_pred_lr_test = lr_best.predict(X_test)\n",
        "y_pred_lr_train = lr_best.predict(X_train)\n",
        "\n",
        "# Evaluation\n",
        "lr_accuracy_test = accuracy_score(y_test, y_pred_lr_test)\n",
        "lr_accuracy_train = accuracy_score(y_train, y_pred_lr_train)\n",
        "lr_report = classification_report(y_test, y_pred_lr_test, output_dict=True)\n",
        "\n",
        "print(\"Accuracy using Logistic Regression =\", lr_accuracy_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "j8Kwsb2FQ5tt",
      "metadata": {
        "id": "j8Kwsb2FQ5tt"
      },
      "source": [
        "Classification Report for Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14cf0678",
      "metadata": {
        "id": "14cf0678",
        "outputId": "f1330c26-4017-4f95-b9eb-91a4e7045ff0"
      },
      "outputs": [],
      "source": [
        "# Transform classification report into DataFrame\n",
        "lr_report_df = pd.DataFrame(lr_report).transpose()\n",
        "\n",
        "# Plotting the classification report\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(data=lr_report_df.iloc[:-1, :].drop(columns=['support']), annot=True, cmap='Blues', fmt='.2f')\n",
        "plt.title('Logistic Regression Classification Report')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LkEwihEvQ93M",
      "metadata": {
        "id": "LkEwihEvQ93M"
      },
      "source": [
        "Confusion Matrix for Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e7234bd",
      "metadata": {
        "id": "6e7234bd",
        "outputId": "fb405b4f-292a-44f5-f19a-8ba9db23d34e"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred_lr_test), annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Logistic Regression Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "njtjcXoKIl5z",
      "metadata": {
        "id": "njtjcXoKIl5z"
      },
      "source": [
        "#### Implementing Artificial Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-aGwA0KmRD4E",
      "metadata": {
        "id": "-aGwA0KmRD4E"
      },
      "source": [
        "Encoding the target values for application of ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "321fc966",
      "metadata": {
        "id": "321fc966"
      },
      "outputs": [],
      "source": [
        "encoder = LabelEncoder()\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "y_test = encoder.fit_transform(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6-FHMFW3RPBh",
      "metadata": {
        "id": "6-FHMFW3RPBh"
      },
      "source": [
        "Applying the model with the hidden layers with different number of neurons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff5e4225",
      "metadata": {
        "id": "ff5e4225"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(256, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "    Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c359d8f",
      "metadata": {
        "id": "1c359d8f"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zmx3JlKTRXjv",
      "metadata": {
        "id": "zmx3JlKTRXjv"
      },
      "source": [
        "Saving the Weights & Bias of the trained model in genre_classifier.keras file for ease of computation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9028215b",
      "metadata": {
        "id": "9028215b"
      },
      "outputs": [],
      "source": [
        "try :\n",
        "    class History():\n",
        "        def __init__(self, history):\n",
        "            self.history = history\n",
        "    model = (load_model('genre_classifier.keras'))\n",
        "    with open('model_history.pkl', 'rb') as file:\n",
        "        loaded_history = pickle.load(file)\n",
        "    history = History(loaded_history)\n",
        "    \n",
        "        \n",
        "except:\n",
        "    history = model.fit(X_train, y_train, epochs=70, validation_data=(X_test, y_test), verbose=0)\n",
        "    with open('model_history.pkl', 'wb') as file:\n",
        "        pickle.dump(history.history, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84a2b07f",
      "metadata": {
        "id": "84a2b07f"
      },
      "outputs": [],
      "source": [
        "model.save('genre_classifier.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EsYbMJITRpQ8",
      "metadata": {
        "id": "EsYbMJITRpQ8"
      },
      "source": [
        "Plotting the Loss Curve with epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bac6e0ee",
      "metadata": {
        "id": "bac6e0ee",
        "outputId": "db6f4840-fda5-4e47-a602-171568b114f2"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.title('Loss Curve')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RxVmppcFRsHm",
      "metadata": {
        "id": "RxVmppcFRsHm"
      },
      "source": [
        "Plotting the Accuracy Curve with epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f35167ac",
      "metadata": {
        "id": "f35167ac",
        "outputId": "4a6e49ff-3a38-49ca-af46-ae26243d14fc"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'], label='train')\n",
        "plt.plot(history.history['val_accuracy'], label='test')\n",
        "plt.title('Accuracy Curve')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VsbhBw7QR005",
      "metadata": {
        "id": "VsbhBw7QR005"
      },
      "source": [
        "Function to predict the Genre of audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cafe623c",
      "metadata": {
        "id": "cafe623c"
      },
      "outputs": [],
      "source": [
        "def predictANN(data):\n",
        "    return encoder.classes_[np.argmax(model.predict(data), axis=1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HrC5M4KoR8L1",
      "metadata": {
        "id": "HrC5M4KoR8L1"
      },
      "source": [
        "Computing the train & test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "399a5a97",
      "metadata": {
        "id": "399a5a97",
        "outputId": "1e87d320-ae09-41c7-8d98-3a5693059229"
      },
      "outputs": [],
      "source": [
        "y_test_pred_ANN = np.argmax(model.predict(X_test), axis=1)\n",
        "ann_accuracy_test = accuracy_score(y_test_pred_ANN, y_test)\n",
        "print(\"Test accuracy using ANN =\", ann_accuracy_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ba49850",
      "metadata": {
        "id": "4ba49850",
        "outputId": "6ebc4a06-7824-4c14-a4ce-c86ef4a69f23"
      },
      "outputs": [],
      "source": [
        "y_train_pred_ANN = np.argmax(model.predict(X_train), axis=1)\n",
        "ann_accuracy_train = accuracy_score(y_train_pred_ANN, y_train)\n",
        "print(\"Train accuracy using ANN =\", ann_accuracy_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ua1D-wxjSAd3",
      "metadata": {
        "id": "Ua1D-wxjSAd3"
      },
      "source": [
        "Classification Report for Artificial Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8989083",
      "metadata": {
        "id": "d8989083",
        "outputId": "e78b78de-2bf4-4457-8080-4d9f643f57a5"
      },
      "outputs": [],
      "source": [
        "ANN_report = classification_report(y_test, y_test_pred_ANN, output_dict=True)\n",
        "\n",
        "# Transform classification report into DataFrame\n",
        "ANN_report_df = pd.DataFrame(ANN_report).transpose()\n",
        "\n",
        "# Plotting the classification report\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(data=lr_report_df.iloc[:-1, :].drop(columns=['support']), annot=True, cmap='Blues', fmt='.2f')\n",
        "plt.title('ANN Classification Report')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BtxZ1rLCSFjm",
      "metadata": {
        "id": "BtxZ1rLCSFjm"
      },
      "source": [
        "Confusion Matrix for Artificial Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7a44a1e",
      "metadata": {
        "id": "c7a44a1e",
        "outputId": "bb8a76c1-35e3-43e6-9693-ebb61a6ddd7b"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_matrix(y_test, y_test_pred_ANN), annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('ANN Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "U4sCXI2kPB9E",
      "metadata": {
        "id": "U4sCXI2kPB9E"
      },
      "source": [
        "#### Comparing the train & test Accuracies of different models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd5beeb0",
      "metadata": {
        "id": "fd5beeb0",
        "outputId": "95c0df2c-e199-4d04-fc5c-0f08fa918ce2"
      },
      "outputs": [],
      "source": [
        "models = ['KNN', 'Decision Tree', 'SVM', 'Adaboost', 'Logistic Regression', 'ANN']\n",
        "\n",
        "index = np.arange(len(models))\n",
        "bar_width = 0.35\n",
        "\n",
        "# Corresponding accuracies\n",
        "test_accuracies = [knn_accuracy_test, dt_accuracy_test, svm_accuracy_test, adaboost_accuracy_test, lr_accuracy_test, ann_accuracy_test]\n",
        "train_accuracies = [knn_accuracy_train, dt_accuracy_train, svm_accuracy_train, adaboost_accuracy_train, lr_accuracy_train, ann_accuracy_train]\n",
        "\n",
        "# Creating the bar chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.bar(index, test_accuracies, bar_width, label='Test Accuracy', color=\"skyblue\", edgecolor='black')\n",
        "plt.bar(index + bar_width, train_accuracies, bar_width, label='Train Accuracy', color=\"mistyrose\", edgecolor='black')\n",
        "\n",
        "# Adding text labels\n",
        "for i in range(len(index)):\n",
        "    plt.text(i, test_accuracies[i] + 0.005, f'{test_accuracies[i]*100:.2f}%', ha='center', va='bottom', fontsize=10)\n",
        "    plt.text(i + bar_width, train_accuracies[i] + 0.005, f'{train_accuracies[i]*100:.2f}%', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "plt.xlabel('Models', fontsize=12)\n",
        "plt.ylabel('Accuracy', fontsize=12)\n",
        "plt.title('Comparison of Model Accuracies', fontsize=14)\n",
        "plt.xticks(index + bar_width / 2, models, rotation=45, ha='right', fontsize=10)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "h-_bJS7CIt1q",
      "metadata": {
        "id": "h-_bJS7CIt1q"
      },
      "source": [
        "## Functions for inferring Genres of new audio data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mOrmnMf2SOmQ",
      "metadata": {
        "id": "mOrmnMf2SOmQ"
      },
      "source": [
        "Implementation of a function to compute the audio features and apply PCA to reduce the number of features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1cd2015-ab6f-41f4-9dd4-ba8ac0ea0163",
      "metadata": {
        "id": "d1cd2015-ab6f-41f4-9dd4-ba8ac0ea0163"
      },
      "outputs": [],
      "source": [
        "path = \"Data/genres_original/blues/blues.00000.wav\"\n",
        "\n",
        "def music_transform(path):\n",
        "\n",
        "    if \".mp3\" in path:\n",
        "        y, sr = sf.read(path)\n",
        "\n",
        "        if len(y.shape) > 1:\n",
        "            y = librosa.to_mono(y.T)\n",
        "\n",
        "    y, sr = librosa.load(path)\n",
        "\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
        "\n",
        "    mfccs_mean = np.mean(mfccs,axis = 1)\n",
        "    mfccs_var = np.var(mfccs, axis = 1)\n",
        "    rms = librosa.feature.rms(y=y)\n",
        "    chromagram = librosa.feature.chroma_stft(y=y, sr=sr)\n",
        "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
        "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
        "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y)\n",
        "    spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
        "    y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
        "    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
        "\n",
        "    data_array = []\n",
        "    features = [chromagram,rms,spectral_centroid,spectral_bandwidth,spectral_rolloff,zero_crossing_rate,y_harmonic,y_percussive]\n",
        "\n",
        "    for i in features:\n",
        "        data_array.append(np.mean(i))\n",
        "        data_array.append(np.var(i))\n",
        "\n",
        "    data_array.append(tempo)\n",
        "\n",
        "    for i in range(20):\n",
        "        data_array.append(mfccs_mean[i])\n",
        "        data_array.append(mfccs_var[i])\n",
        "\n",
        "    music_data = pd.DataFrame(np.array(data_array).reshape(1,57),columns = ['chroma_stft_mean', 'chroma_stft_var', 'rms_mean', 'rms_var',\n",
        "       'spectral_centroid_mean', 'spectral_centroid_var',\n",
        "       'spectral_bandwidth_mean', 'spectral_bandwidth_var', 'rolloff_mean',\n",
        "       'rolloff_var', 'zero_crossing_rate_mean', 'zero_crossing_rate_var',\n",
        "       'harmony_mean', 'harmony_var', 'perceptr_mean', 'perceptr_var', 'tempo',\n",
        "       'mfcc1_mean', 'mfcc1_var', 'mfcc2_mean', 'mfcc2_var', 'mfcc3_mean',\n",
        "       'mfcc3_var', 'mfcc4_mean', 'mfcc4_var', 'mfcc5_mean', 'mfcc5_var',\n",
        "       'mfcc6_mean', 'mfcc6_var', 'mfcc7_mean', 'mfcc7_var', 'mfcc8_mean',\n",
        "       'mfcc8_var', 'mfcc9_mean', 'mfcc9_var', 'mfcc10_mean', 'mfcc10_var',\n",
        "       'mfcc11_mean', 'mfcc11_var', 'mfcc12_mean', 'mfcc12_var', 'mfcc13_mean',\n",
        "       'mfcc13_var', 'mfcc14_mean', 'mfcc14_var', 'mfcc15_mean', 'mfcc15_var',\n",
        "       'mfcc16_mean', 'mfcc16_var', 'mfcc17_mean', 'mfcc17_var', 'mfcc18_mean',\n",
        "       'mfcc18_var', 'mfcc19_mean', 'mfcc19_var', 'mfcc20_mean', 'mfcc20_var'])\n",
        "    scaled_data_music = scaler.transform(music_data)\n",
        "\n",
        "    scaled_dataframe = pd.DataFrame(scaled_data_music, columns = music_data.columns)\n",
        "\n",
        "    musicpca_components = pca.transform(scaled_dataframe)\n",
        "\n",
        "    music_pca = pd.DataFrame(musicpca_components)\n",
        "    return music_pca\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1k_QgzTzSoA4",
      "metadata": {
        "id": "1k_QgzTzSoA4"
      },
      "source": [
        "Function which takes path of audio file and name of classifier to predict the Genre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "913c9c77-6efa-4295-bc3d-9744f28df980",
      "metadata": {
        "id": "913c9c77-6efa-4295-bc3d-9744f28df980"
      },
      "outputs": [],
      "source": [
        "def modelPrediction(path, classifier = \"KNN\"):\n",
        "\n",
        "    music_data = music_transform(path)\n",
        "\n",
        "    if classifier == \"KNN\":\n",
        "        return knn_best.predict(music_data)\n",
        "    elif classifier == \"Decision Tree\":\n",
        "        return dt_best.predict(music_data)\n",
        "    elif classifier == \"SVM\":\n",
        "        return svm_best.predict(music_data)\n",
        "    elif classifier == \"Adaboost\":\n",
        "        return adaboost_best.predict(music_data)\n",
        "    elif classifier == \"Logistic Regression\":\n",
        "        return lr_best.predict(music_data)\n",
        "    elif classifier == \"ANN\":\n",
        "        return predictANN(music_data)\n",
        "    else:\n",
        "        return \"Model Not Found\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7770ae69-eea4-421a-9654-f7ed365993ec",
      "metadata": {
        "id": "7770ae69-eea4-421a-9654-f7ed365993ec",
        "outputId": "313f10b2-972d-416b-9fe1-45e0c5848e85"
      },
      "outputs": [],
      "source": [
        "print(\"According to KNN the audio is\", modelPrediction(path,\"KNN\"))\n",
        "print(\"According to Decision Tree the audio is\", modelPrediction(path,\"Decision Tree\"))\n",
        "print(\"According to SVM the audio is\", modelPrediction(path,\"SVM\"))\n",
        "print(\"According to Adaboost the audio is\", modelPrediction(path,\"Adaboost\"))\n",
        "print(\"According to Logistic Regression the audio is\", modelPrediction(path,\"Logistic Regression\"))\n",
        "print(\"According to ANN the audio is\", modelPrediction(path,\"ANN\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd3ccc8d",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
